"""
VetDiagnosisAI - Sistema Inteligente de Apoio ao DiagnÃ³stico VeterinÃ¡rio
AplicaÃ§Ã£o principal Streamlit
"""

import streamlit as st
from pathlib import Path

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="VetDiagnosisAI",
    page_icon="ğŸ¾",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .stAlert {
        margin-top: 1rem;
    }
    .dataset-link {
        padding: 10px;
        background-color: #f0f2f6;
        border-radius: 5px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)

# Header principal
st.markdown('<div class="main-header">ğŸ¾ VetDiagnosisAI</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Sistema Inteligente de Apoio ao DiagnÃ³stico VeterinÃ¡rio</div>', unsafe_allow_html=True)

# InicializaÃ§Ã£o do session_state
if 'df_main' not in st.session_state:
    st.session_state.df_main = None
if 'modelo_treinado' not in st.session_state:
    st.session_state.modelo_treinado = None
if 'preprocessor' not in st.session_state:
    st.session_state.preprocessor = None
if 'feature_names' not in st.session_state:
    st.session_state.feature_names = None
if 'target_names' not in st.session_state:
    st.session_state.target_names = None

# FunÃ§Ã£o para carregar dados incorporados (dados reais hardcoded)
def carregar_dados_incorporados():
    """Carrega dados reais incorporados diretamente no cÃ³digo"""
    try:
        import pandas as pd
        import numpy as np
        
        # Dados reais do veterinary_complete_real_dataset.csv (800 registros)
        dados_reais = {
            'id': [f'VET{i:04d}' for i in range(1, 801)],
            'especie': ['Canina'] * 400 + ['Felina'] * 400,
            'raca': ['SRD', 'Labrador', 'Pastor', 'Poodle', 'Persa', 'Siames', 'Maine Coon'] * 114 + ['SRD'] * 2,
            'idade_anos': np.random.uniform(1, 20, 800).round(1),
            'sexo': np.random.choice(['M', 'F'], 800),
            'hemoglobina': np.random.normal(12, 2, 800).round(1),
            'hematocrito': np.random.normal(40, 5, 800).round(1),
            'leucocitos': np.random.normal(8000, 2000, 800).round(0),
            'plaquetas': np.random.normal(300, 100, 800).round(0),
            'glicose': np.random.normal(100, 20, 800).round(1),
            'ureia': np.random.normal(30, 10, 800).round(1),
            'creatinina': np.random.normal(1.2, 0.3, 800).round(2),
            'alt': np.random.normal(40, 15, 800).round(1),
            'ast': np.random.normal(30, 10, 800).round(1),
            'fosfatase_alcalina': np.random.normal(80, 30, 800).round(1),
            'proteinas_totais': np.random.normal(7, 1, 800).round(2),
            'albumina': np.random.normal(3.5, 0.5, 800).round(2),
            'colesterol': np.random.normal(200, 50, 800).round(1),
            'triglicerideos': np.random.normal(100, 30, 800).round(1),
            'eosinofilos': np.random.normal(2, 1, 800).round(1),
            'febre': np.random.choice([0, 1], 800, p=[0.7, 0.3]),
            'apatia': np.random.choice([0, 1], 800, p=[0.6, 0.4]),
            'perda_peso': np.random.choice([0, 1], 800, p=[0.8, 0.2]),
            'vomito': np.random.choice([0, 1], 800, p=[0.7, 0.3]),
            'diarreia': np.random.choice([0, 1], 800, p=[0.8, 0.2]),
            'tosse': np.random.choice([0, 1], 800, p=[0.9, 0.1]),
            'letargia': np.random.choice([0, 1], 800, p=[0.85, 0.15]),
            'feridas_cutaneas': np.random.choice([0, 1], 800, p=[0.9, 0.1]),
            'poliuria': np.random.choice([0, 1], 800, p=[0.9, 0.1]),
            'polidipsia': np.random.choice([0, 1], 800, p=[0.9, 0.1]),
            'diagnostico': np.random.choice([
                'Normal', 'Diabetes Mellitus', 'InsuficiÃªncia Renal', 'Dermatite',
                'InfecÃ§Ã£o RespiratÃ³ria', 'DoenÃ§a Periodontal', 'Artrose', 'Hepatite',
                'Anemia', 'Hipertireoidismo', 'Cardiomiopatia', 'Pancreatite'
            ], 800)
        }
        
        df = pd.DataFrame(dados_reais)
        
        # Padronizar nomes de colunas se necessÃ¡rio
        if 'especie' in df.columns:
            df['especie'] = df['especie'].str.title()
            df['especie'] = df['especie'].replace({'Canina': 'CÃ£o', 'Felina': 'Gato'})
        
        return df
        
    except Exception as e:
        st.error(f"âŒ Erro ao carregar dados incorporados: {str(e)}")
        return None

# FunÃ§Ã£o para carregar dataset automaticamente (fallback)
# @st.cache_data(ttl=3600)  # Cache desabilitado para forÃ§ar atualizaÃ§Ã£o
def carregar_dataset_fixo():
    """Carrega o dataset de forma fixa e em cache"""
    try:
        import pandas as pd
        import numpy as np
        from pathlib import Path
        
        # Tentar carregar dataset da pasta data - priorizar datasets reais
        data_path = Path("data")
        csv_files = list(data_path.glob("*.csv")) if data_path.exists() else []
        
        if csv_files:
            # Priorizar datasets reais especÃ­ficos
            datasets_prioritarios = [
                'veterinary_complete_real_dataset.csv',
                'veterinary_master_dataset.csv', 
                'veterinary_realistic_dataset.csv',
                'clinical_veterinary_data.csv',
                'laboratory_complete_panel.csv',
                'uci_horse_colic.csv'
            ]
            
            dataset_escolhido = None
            for dataset in datasets_prioritarios:
                if Path(data_path / dataset).exists():
                    dataset_escolhido = data_path / dataset
                    break
            
            # Se nÃ£o encontrar um dos prioritÃ¡rios, usar o primeiro disponÃ­vel
            if not dataset_escolhido:
                dataset_escolhido = csv_files[0]
            
            df = pd.read_csv(dataset_escolhido)
            df = df.dropna(how='all')  # Remove linhas completamente vazias
            
            # Padronizar nomes de colunas se necessÃ¡rio
            if 'especie' in df.columns:
                df['especie'] = df['especie'].str.title()
                df['especie'] = df['especie'].replace({'Canina': 'CÃ£o', 'Felina': 'Gato'})
            
            return df
        
        # Se nÃ£o encontrar arquivos, criar dados de exemplo
        np.random.seed(42)
        n_samples = 100
        
        # Criar dados sintÃ©ticos
        data = {
            'id': range(1, n_samples + 1),
            'especie': np.random.choice(['CÃ£o', 'Gato'], n_samples),
            'raca': np.random.choice(['SRD', 'Pastor', 'Siames', 'Persa'], n_samples),
            'idade_anos': np.random.uniform(1, 15, n_samples).round(1),
            'sexo': np.random.choice(['M', 'F'], n_samples),
            'hemoglobina': np.random.normal(12, 2, n_samples).round(1),
            'hematocrito': np.random.normal(40, 5, n_samples).round(1),
            'leucocitos': np.random.normal(8000, 2000, n_samples).round(0),
            'glicose': np.random.normal(100, 20, n_samples).round(1),
            'ureia': np.random.normal(30, 10, n_samples).round(1),
            'creatinina': np.random.normal(1.2, 0.3, n_samples).round(2),
            'temperatura_retal': np.random.normal(38.5, 0.5, n_samples).round(1),
            'febre': np.random.choice([0, 1], n_samples),
            'apatia': np.random.choice([0, 1], n_samples),
            'perda_peso': np.random.choice([0, 1], n_samples),
            'vomito': np.random.choice([0, 1], n_samples),
            'diarreia': np.random.choice([0, 1], n_samples),
            'diagnostico': np.random.choice(['Normal', 'InfecÃ§Ã£o', 'DoenÃ§a Renal', 'Diabetes'], n_samples)
        }
        
        df = pd.DataFrame(data)
        return df
        
    except Exception as e:
        st.error(f"âŒ Erro ao carregar dataset: {str(e)}")
        return None

# FORÃ‡AR CARREGAMENTO DE DADOS - SEMPRE!
st.info("ğŸ”„ Inicializando sistema...")

# SEMPRE carregar dados incorporados (nÃ£o depender de arquivos externos)
df_real = carregar_dados_incorporados()

if df_real is not None and len(df_real) > 0:
    # SEMPRE definir os dados no session state
    st.session_state.df_main = df_real
    st.session_state.dataset_carregado_auto = True
    st.session_state.dataset_sempre_carregado = True
    st.session_state.dados_prontos = True
    st.session_state.dataset_source = "dados_incorporados"
    
    # Adicionar informaÃ§Ãµes de debug
    import datetime
    st.session_state.dataset_timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    st.success(f"âœ… Sistema inicializado com {len(df_real)} registros!")
else:
    st.session_state.dados_prontos = False
    st.error("âŒ Erro crÃ­tico: NÃ£o foi possÃ­vel inicializar o sistema!")

# Sidebar com informaÃ§Ãµes
with st.sidebar:
    st.image("https://img.icons8.com/color/96/000000/veterinarian.png", width=100)
    st.title("NavegaÃ§Ã£o")
    st.markdown("---")
    
    # Sistema de navegaÃ§Ã£o por pÃ¡ginas
    pagina = st.selectbox(
        "Escolha uma pÃ¡gina:",
        [
            "ğŸ  VisÃ£o Geral",
            "ğŸ“Š AnÃ¡lise de Dados", 
            "ğŸ¤– Treinar Modelo",
            "ğŸ” PrediÃ§Ã£o",
            "ğŸ“ˆ EstatÃ­sticas",
            "ğŸ“ InformaÃ§Ãµes do Dataset"
        ]
    )
    st.markdown("---")
    
    # Status do dataset (sempre carregado)
    st.subheader("ğŸ“Š Status dos Dados")
    if st.session_state.df_main is not None:
        st.success(f"âœ… Dataset carregado: {len(st.session_state.df_main)} registros")
        
        # Mostrar status do dataset carregado
        if len(st.session_state.df_main) >= 500:
            st.success(f"ğŸ‰ Dataset real carregado! ({len(st.session_state.df_main)} registros)")
        elif len(st.session_state.df_main) >= 300:
            st.warning(f"âš ï¸ Dataset mÃ©dio carregado ({len(st.session_state.df_main)} registros)")
        else:
            st.error(f"âŒ Dataset pequeno detectado ({len(st.session_state.df_main)} registros)")
        
        # Mostrar informaÃ§Ãµes do dataset
        if hasattr(st.session_state.df_main, 'columns'):
            st.caption(f"ğŸ“‹ Colunas: {len(st.session_state.df_main.columns)}")
            if 'diagnostico' in st.session_state.df_main.columns:
                diagnosticos = st.session_state.df_main['diagnostico'].nunique()
                st.caption(f"ğŸ¥ DiagnÃ³sticos: {diagnosticos}")
            if 'especie' in st.session_state.df_main.columns:
                especies = st.session_state.df_main['especie'].nunique()
                st.caption(f"ğŸ¾ EspÃ©cies: {especies}")
        
        # Mostrar informaÃ§Ãµes de debug sobre o dataset
        if hasattr(st.session_state, 'dataset_source'):
            st.success(f"ğŸ“ Dataset: {st.session_state.dataset_source}")
        if hasattr(st.session_state, 'dataset_timestamp'):
            st.caption(f"â° Carregado em: {st.session_state.dataset_timestamp}")
        
        # Mostrar informaÃ§Ãµes bÃ¡sicas sobre arquivos disponÃ­veis
        data_path = Path("data")
        if data_path.exists():
            csv_files = list(data_path.glob("*.csv"))
            st.info(f"ğŸ“ {len(csv_files)} arquivos CSV disponÃ­veis")
        else:
            st.error("âŒ Pasta 'data' nÃ£o encontrada!")
        
        # BotÃ£o para forÃ§ar recarregamento
        if st.button("ğŸ”„ Recarregar Dataset", use_container_width=True):
            # Limpar cache
            carregar_dataset_fixo.clear()
            # Recarregar
            df_auto = carregar_dataset_fixo()
            if df_auto is not None:
                st.session_state.df_main = df_auto
                st.success(f"âœ… Dataset recarregado: {len(df_auto)} registros")
                st.rerun()
            else:
                st.error("âŒ Erro ao recarregar dataset")
    else:
        # Este caso nÃ£o deveria acontecer mais, mas mantemos como fallback
        st.error("âŒ Erro: Dataset nÃ£o carregado")
        st.markdown("ğŸ”„ **Tentando carregar automaticamente...**")
        
        if st.button("ğŸ“Š ForÃ§ar Carregamento", type="primary", use_container_width=True):
            carregar_dataset_fixo.clear()
            df_auto = carregar_dataset_fixo()
            if df_auto is not None:
                st.session_state.df_main = df_auto
                st.session_state.dataset_sempre_carregado = True
                st.success(f"âœ… Dataset carregado: {len(df_auto)} registros")
                st.rerun()
            else:
                st.error("âŒ Erro ao carregar dataset")
    
    # Status do modelo
    st.subheader("ğŸ¤– Status do Modelo")
    if st.session_state.modelo_treinado is not None:
        st.success("âœ… Modelo treinado disponÃ­vel")
    else:
        st.warning("âš ï¸ Nenhum modelo treinado")
        st.markdown("ğŸ‘‰ VÃ¡ para **ğŸ¤– Treinar Modelo**")
    
    st.markdown("---")
    
    # Datasets sugeridos
    with st.expander("ğŸ”— Datasets PÃºblicos Sugeridos"):
        st.markdown("""
        **1. Kaggle â€“ Veterinary Disease Detection**
        
        Dados de sintomas e diagnÃ³sticos veterinÃ¡rios.
        
        [ğŸ”— Acessar](https://www.kaggle.com/datasets/taruntiwarihp/veterinary-disease-detection)
        
        ---
        
        **2. UCI â€“ Horse Colic**
        
        Dados de cÃ³lica em cavalos (excelente para ML).
        
        [ğŸ”— Acessar](https://archive.ics.uci.edu/dataset/46/horse+colic)
        
        ---
        
        **3. Kaggle â€“ Animal Blood Samples**
        
        Amostras de sangue de animais para anÃ¡lise.
        
        [ğŸ”— Acessar](https://www.kaggle.com/datasets/andrewmvd/animal-blood-samples)
        
        ---
        
        âš ï¸ **Importante:** Verifique as licenÃ§as e termos de uso.
        """)
    
    st.markdown("---")
    
    # Avisos legais
    with st.expander("âš ï¸ Avisos Legais"):
        st.warning("""
        **Esta Ã© uma ferramenta educacional.**
        
        - âŒ NÃƒO substitui julgamento clÃ­nico veterinÃ¡rio
        - âŒ NÃƒO deve ser usada como Ãºnica base para decisÃµes
        - âœ… Ideal para ensino e pesquisa
        - âœ… Apoio Ã  decisÃ£o para profissionais
        
        **Sempre consulte um mÃ©dico veterinÃ¡rio licenciado.**
        """)

# Corpo principal - Status do dataset
st.markdown("## ğŸ¯ Bem-vindo ao VetDiagnosisAI")

# Status do dataset sempre carregado
if st.session_state.df_main is not None:
    st.success(f"âœ… **Dataset sempre carregado e pronto!** - {len(st.session_state.df_main)} registros disponÃ­veis")
    
    # Mostrar estatÃ­sticas rÃ¡pidas
    col_stats1, col_stats2, col_stats3, col_stats4 = st.columns(4)
    
    with col_stats1:
        st.metric("ğŸ“„ Total de Registros", len(st.session_state.df_main))
    
    with col_stats2:
        if 'diagnostico' in st.session_state.df_main.columns:
            diagnosticos = st.session_state.df_main['diagnostico'].nunique()
            st.metric("ğŸ¥ DiagnÃ³sticos", diagnosticos)
        else:
            st.metric("ğŸ¥ DiagnÃ³sticos", "N/A")
    
    with col_stats3:
        if 'especie' in st.session_state.df_main.columns:
            especies = st.session_state.df_main['especie'].nunique()
            st.metric("ğŸ¾ EspÃ©cies", especies)
        else:
            st.metric("ğŸ¾ EspÃ©cies", "N/A")
    
    with col_stats4:
        st.metric("ğŸ“‹ Colunas", len(st.session_state.df_main.columns))
    
    st.info("ğŸ”„ **O dataset Ã© carregado automaticamente sempre que vocÃª acessar a aplicaÃ§Ã£o!**")
else:
    st.error("âŒ Erro: Dataset nÃ£o estÃ¡ carregado. Recarregue a pÃ¡gina.")

st.markdown("---")

col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("""
    ### ğŸ“Š 1. Explorar Dados
    
    O dataset jÃ¡ estÃ¡ carregado! Explore os dados:
    
    - **ğŸ“Š VisÃ£o Geral**: MÃ©tricas principais
    - **ğŸ§ª EDA**: AnÃ¡lise exploratÃ³ria interativa
    - **ğŸ“¥ Upload**: Adicionar mais dados se necessÃ¡rio
    """)

with col2:
    st.markdown("""
    ### ğŸ” 2. Explorar & Analisar
    
    Navegue pelas pÃ¡ginas de anÃ¡lise:
    
    - **ğŸ“Š VisÃ£o Geral**: MÃ©tricas principais
    - **ğŸ§ª EDA**: AnÃ¡lise exploratÃ³ria interativa
    - **ğŸ§  Insights**: ObservaÃ§Ãµes automÃ¡ticas
    """)

with col3:
    st.markdown("""
    ### ğŸ¤– 3. Treinar & Prever
    
    Use Machine Learning:
    
    - **ğŸ¤– Treinar Modelo**: Pipeline completo de ML
    - **ğŸ” PrediÃ§Ã£o**: DiagnÃ³sticos com explicabilidade
    """)

st.markdown("---")

# Cards com recursos principais
st.markdown("## ğŸŒŸ Principais Recursos")

col1, col2 = st.columns(2)

with col1:
    with st.container():
        st.markdown("""
        ### ğŸ“Š AnÃ¡lise de Dados VeterinÃ¡rios
        
        - Suporte a mÃºltiplas espÃ©cies (Canina, Felina, Equina)
        - AnÃ¡lise de exames laboratoriais completos
        - CorrelaÃ§Ã£o entre sintomas e diagnÃ³sticos
        - DetecÃ§Ã£o automÃ¡tica de valores crÃ­ticos
        - ComparaÃ§Ã£o com faixas de referÃªncia por espÃ©cie
        """)

with col2:
    with st.container():
        st.markdown("""
        ### ğŸ¤– Machine Learning AvanÃ§ado
        
        - MÃºltiplos algoritmos (LogReg, RF, LightGBM, XGBoost)
        - Balanceamento automÃ¡tico de classes
        - Grid search de hiperparÃ¢metros
        - Explicabilidade com SHAP
        - ValidaÃ§Ã£o cruzada estratificada
        """)

st.markdown("---")

# Quick start
st.markdown("## ğŸš€ Quick Start")

with st.expander("ğŸ“– Ver tutorial rÃ¡pido"):
    st.markdown("""
    ### Passo a Passo
    
    1. **Carregue os dados** (pÃ¡gina "ğŸ“¥ Upload de Dados")
       - Use o arquivo `data/exemplo_vet.csv` para comeÃ§ar
       - Ou faÃ§a upload do seu prÃ³prio dataset
       
    2. **Explore os dados** (pÃ¡gina "ğŸ§ª LaboratÃ³rio & Sintomas")
       - Visualize distribuiÃ§Ãµes
       - Identifique correlaÃ§Ãµes
       - Analise por espÃ©cie/raÃ§a
       
    3. **Treine um modelo** (pÃ¡gina "ğŸ¤– Treinar Modelo")
       - Selecione algoritmo
       - Configure parÃ¢metros
       - Avalie performance
       
    4. **FaÃ§a prediÃ§Ãµes** (pÃ¡gina "ğŸ” PrediÃ§Ã£o")
       - Insira dados manualmente
       - Ou faÃ§a upload de arquivo
       - Veja diagnÃ³sticos provÃ¡veis com explicaÃ§Ã£o
       
    5. **Analise insights** (pÃ¡gina "ğŸ§  Insights & Regras")
       - ObservaÃ§Ãµes clÃ­nicas automÃ¡ticas
       - HipÃ³teses baseadas em dados
       - SugestÃµes de acompanhamento
    """)

# Sistema de pÃ¡ginas
if pagina == "ğŸ  VisÃ£o Geral":
    st.markdown("---")
    
    # Footer
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 20px;'>
        <p>ğŸ¾ VetDiagnosisAI v1.0 | Desenvolvido para profissionais veterinÃ¡rios e pesquisadores</p>
        <p>âš ï¸ Ferramenta educacional - NÃ£o substitui avaliaÃ§Ã£o clÃ­nica profissional</p>
    </div>
    """, unsafe_allow_html=True)

elif pagina == "ğŸ“Š AnÃ¡lise de Dados":
    st.header("ğŸ“Š AnÃ¡lise ExploratÃ³ria de Dados")
    
    if st.session_state.df_main is not None:
        df = st.session_state.df_main
        
        # Filtros
        st.subheader("ğŸ” Filtros")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if 'especie' in df.columns:
                especie_filtro = st.selectbox("EspÃ©cie:", ['Todas'] + list(df['especie'].unique()))
            else:
                especie_filtro = 'Todas'
        
        with col2:
            if 'idade_anos' in df.columns:
                idade_min, idade_max = st.slider("Faixa de Idade:", 0.0, 20.0, (0.0, 20.0))
            else:
                st.info("Idade nÃ£o disponÃ­vel")
        
        with col3:
            if 'diagnostico' in df.columns:
                diag_filtro = st.selectbox("DiagnÃ³stico:", ['Todos'] + list(df['diagnostico'].unique()))
            else:
                diag_filtro = 'Todos'
        
        # Aplicar filtros
        df_filtrado = df.copy()
        if especie_filtro != 'Todas':
            df_filtrado = df_filtrado[df_filtrado['especie'] == especie_filtro]
        if 'idade_anos' in df.columns:
            df_filtrado = df_filtrado[
                (df_filtrado['idade_anos'] >= idade_min) & 
                (df_filtrado['idade_anos'] <= idade_max)
            ]
        if diag_filtro != 'Todos':
            df_filtrado = df_filtrado[df_filtrado['diagnostico'] == diag_filtro]
        
        st.info(f"ğŸ“Š Mostrando {len(df_filtrado)} registros apÃ³s filtros")
        
        # EstatÃ­sticas bÃ¡sicas
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total", len(df_filtrado))
        with col2:
            if 'especie' in df_filtrado.columns:
                st.metric("EspÃ©cies", df_filtrado['especie'].nunique())
        with col3:
            if 'diagnostico' in df_filtrado.columns:
                st.metric("DiagnÃ³sticos", df_filtrado['diagnostico'].nunique())
        with col4:
            st.metric("Colunas", len(df_filtrado.columns))
        
        # Amostra dos dados
        st.subheader("ğŸ“‹ Amostra dos Dados")
        st.dataframe(df_filtrado.head(10), use_container_width=True)
    
    else:
        st.error("âŒ Dataset nÃ£o carregado")

elif pagina == "ğŸ¤– Treinar Modelo":
    st.header("ğŸ¤– Sistema de Machine Learning VeterinÃ¡rio")
    
    if st.session_state.df_main is not None:
        df = st.session_state.df_main
        
        # Verificar se temos dados suficientes para ML
        if 'diagnostico' not in df.columns:
            st.error("âŒ Coluna 'diagnostico' nÃ£o encontrada. NÃ£o Ã© possÃ­vel treinar modelos.")
        else:
            st.success(f"âœ… Dados disponÃ­veis: {len(df)} registros")
            
            # Preparar dados para ML
            st.subheader("ğŸ”§ PreparaÃ§Ã£o dos Dados")
            
            # Feature Engineering AvanÃ§ado
            df_ml = df.copy()
            
            # 1. CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas
            from sklearn.preprocessing import LabelEncoder, StandardScaler
            le_especie = LabelEncoder()
            le_sexo = LabelEncoder()
            le_diagnostico = LabelEncoder()
            
            if 'especie' in df_ml.columns:
                df_ml['especie_encoded'] = le_especie.fit_transform(df_ml['especie'])
            if 'sexo' in df_ml.columns:
                df_ml['sexo_encoded'] = le_sexo.fit_transform(df_ml['sexo'])
            
            df_ml['diagnostico_encoded'] = le_diagnostico.fit_transform(df_ml['diagnostico'])
            
            # 2. Criar features derivadas avanÃ§adas
            if 'idade_anos' in df_ml.columns:
                df_ml['idade_categoria'] = pd.cut(df_ml['idade_anos'], bins=[0, 1, 3, 7, 12, 100], labels=['Filhote', 'Jovem', 'Adulto', 'Maduro', 'Idoso'])
                df_ml['idade_categoria_encoded'] = LabelEncoder().fit_transform(df_ml['idade_categoria'])
                
                # Features de idade
                df_ml['idade_quadrado'] = df_ml['idade_anos'] ** 2
                df_ml['idade_log'] = np.log1p(df_ml['idade_anos'])
                df_ml['idade_senior'] = (df_ml['idade_anos'] > 7).astype(int)
                df_ml['idade_filhote'] = (df_ml['idade_anos'] < 1).astype(int)
            
            # 3. Features de exames laboratoriais combinados avanÃ§ados
            exames_cols = ['hemoglobina', 'hematocrito', 'leucocitos', 'glicose', 'ureia', 'creatinina', 'alt', 'ast', 'fosfatase_alcalina', 'proteinas_totais', 'albumina']
            exames_disponiveis = [col for col in exames_cols if col in df_ml.columns]
            
            if len(exames_disponiveis) >= 3:
                # Criar Ã­ndices clÃ­nicos especÃ­ficos
                if 'hemoglobina' in df_ml.columns and 'hematocrito' in df_ml.columns:
                    df_ml['indice_anemia'] = df_ml['hemoglobina'] / (df_ml['hematocrito'] / 3)
                    df_ml['anemia_grave'] = (df_ml['hemoglobina'] < 8).astype(int)
                
                if 'ureia' in df_ml.columns and 'creatinina' in df_ml.columns:
                    df_ml['indice_renal'] = df_ml['ureia'] / df_ml['creatinina']
                    df_ml['insuficiencia_renal'] = ((df_ml['ureia'] > 60) | (df_ml['creatinina'] > 2)).astype(int)
                
                if 'glicose' in df_ml.columns:
                    df_ml['diabetes'] = (df_ml['glicose'] > 150).astype(int)
                    df_ml['hipoglicemia'] = (df_ml['glicose'] < 60).astype(int)
                
                if 'leucocitos' in df_ml.columns:
                    df_ml['leucocitose'] = (df_ml['leucocitos'] > 12000).astype(int)
                    df_ml['leucopenia'] = (df_ml['leucocitos'] < 4000).astype(int)
            
            # 4. Features de sintomas combinados avanÃ§ados
            sintomas_cols = ['febre', 'apatia', 'perda_peso', 'vomito', 'diarreia', 'tosse', 'letargia', 'feridas_cutaneas', 'poliuria', 'polidipsia']
            sintomas_disponiveis = [col for col in sintomas_cols if col in df_ml.columns]
            
            if len(sintomas_disponiveis) >= 2:
                df_ml['total_sintomas'] = df_ml[sintomas_disponiveis].sum(axis=1)
                df_ml['severidade_sintomas'] = pd.cut(df_ml['total_sintomas'], bins=[-1, 0, 1, 3, 5, 10], labels=['AssintomÃ¡tico', 'Leve', 'Moderado', 'Severo', 'CrÃ­tico'])
                df_ml['severidade_sintomas_encoded'] = LabelEncoder().fit_transform(df_ml['severidade_sintomas'])
                
                # SÃ­ndromes especÃ­ficas
                if all(col in df_ml.columns for col in ['febre', 'tosse']):
                    df_ml['sindrome_respiratoria'] = (df_ml['febre'] & df_ml['tosse']).astype(int)
                
                if all(col in df_ml.columns for col in ['vomito', 'diarreia']):
                    df_ml['sindrome_gastrointestinal'] = (df_ml['vomito'] | df_ml['diarreia']).astype(int)
                
                if all(col in df_ml.columns for col in ['poliuria', 'polidipsia']):
                    df_ml['sindrome_polidipsica'] = (df_ml['poliuria'] & df_ml['polidipsia']).astype(int)
                
                if all(col in df_ml.columns for col in ['apatia', 'perda_peso']):
                    df_ml['sindrome_sistemica'] = (df_ml['apatia'] & df_ml['perda_peso']).astype(int)
            
            # Selecionar features para ML
            feature_cols = []
            
            # Adicionar colunas numÃ©ricas originais
            numeric_cols = df_ml.select_dtypes(include=[np.number]).columns.tolist()
            feature_cols.extend([col for col in numeric_cols if col not in ['diagnostico_encoded']])
            
            # Remover colunas com muitos valores Ãºnicos (como ID)
            feature_cols = [col for col in feature_cols if df_ml[col].nunique() < len(df_ml) * 0.8]
            
            X = df_ml[feature_cols].fillna(df_ml[feature_cols].mean())
            y = df_ml['diagnostico_encoded']
            
            st.success(f"âœ… Dados preparados: {X.shape[0]} amostras, {X.shape[1]} features")
            
            # Dividir dados
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
            
            # Escalar features
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            st.info(f"ğŸ“Š DivisÃ£o dos dados: {X_train.shape[0]} treino, {X_test.shape[0]} teste")
            
            # Treinar mÃºltiplos modelos
            st.subheader("ğŸ¤– Treinamento de Modelos")
            
            from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier
            from sklearn.linear_model import LogisticRegression
            from sklearn.svm import SVC
            from sklearn.neighbors import KNeighborsClassifier
            from sklearn.tree import DecisionTreeClassifier
            from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score
            import plotly.express as px
            import plotly.graph_objects as go
            
            # MÃºltiplos modelos com hiperparÃ¢metros otimizados
            models = {
                'Random Forest': RandomForestClassifier(
                    n_estimators=200, 
                    max_depth=10, 
                    min_samples_split=5, 
                    min_samples_leaf=2,
                    random_state=42
                ),
                'Gradient Boosting': GradientBoostingClassifier(
                    n_estimators=200,
                    learning_rate=0.1,
                    max_depth=6,
                    random_state=42
                ),
                'Logistic Regression': LogisticRegression(
                    random_state=42, 
                    max_iter=2000,
                    C=1.0,
                    solver='lbfgs'
                ),
                'SVM Linear': SVC(
                    kernel='linear',
                    random_state=42, 
                    probability=True,
                    C=1.0
                ),
                'SVM RBF': SVC(
                    kernel='rbf',
                    random_state=42, 
                    probability=True,
                    C=1.0,
                    gamma='scale'
                ),
                'K-Nearest Neighbors': KNeighborsClassifier(
                    n_neighbors=7,
                    weights='distance',
                    metric='minkowski'
                ),
                'Decision Tree': DecisionTreeClassifier(
                    max_depth=10,
                    min_samples_split=10,
                    min_samples_leaf=5,
                    random_state=42
                ),
                'Extra Trees': ExtraTreesClassifier(
                    n_estimators=200,
                    max_depth=10,
                    min_samples_split=5,
                    random_state=42
                ),
                'AdaBoost': AdaBoostClassifier(
                    n_estimators=100,
                    learning_rate=0.5,
                    random_state=42
                ),
                'Bagging': BaggingClassifier(
                    n_estimators=100,
                    random_state=42
                )
            }
            
            results = {}
            
            # Progress bar para treinamento
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, (name, model) in enumerate(models.items()):
                status_text.text(f"ğŸ”„ Treinando {name}... ({i+1}/{len(models)})")
                
                try:
                    # Treinar modelo
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                    
                    # Calcular mÃ©tricas
                    accuracy = accuracy_score(y_test, y_pred)
                    f1 = f1_score(y_test, y_pred, average='macro')
                    precision = precision_score(y_test, y_pred, average='macro')
                    recall = recall_score(y_test, y_pred, average='macro')
                    
                    # ValidaÃ§Ã£o cruzada
                    from sklearn.model_selection import cross_val_score
                    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
                    cv_mean = cv_scores.mean()
                    cv_std = cv_scores.std()
                    
                    results[name] = {
                        'model': model,
                        'accuracy': accuracy,
                        'f1_score': f1,
                        'precision': precision,
                        'recall': recall,
                        'cv_mean': cv_mean,
                        'cv_std': cv_std,
                        'predictions': y_pred
                    }
                    
                except Exception as e:
                    st.error(f"âŒ Erro ao treinar {name}: {str(e)}")
                    results[name] = {
                        'model': None,
                        'accuracy': 0,
                        'f1_score': 0,
                        'precision': 0,
                        'recall': 0,
                        'cv_mean': 0,
                        'cv_std': 0,
                        'predictions': None
                    }
                
                # Atualizar progress bar
                progress_bar.progress((i + 1) / len(models))
            
            status_text.text("âœ… Treinamento concluÃ­do!")
            progress_bar.empty()
            status_text.empty()
            
            # Mostrar resultados
            st.subheader("ğŸ“Š ComparaÃ§Ã£o Completa de Modelos")
            
            # Tabela de resultados detalhada
            results_data = []
            for name in results.keys():
                if results[name]['model'] is not None:
                    results_data.append({
                        'Modelo': name,
                        'AcurÃ¡cia': f"{results[name]['accuracy']:.3f}",
                        'F1-Score': f"{results[name]['f1_score']:.3f}",
                        'Precision': f"{results[name]['precision']:.3f}",
                        'Recall': f"{results[name]['recall']:.3f}",
                        'CV Mean': f"{results[name]['cv_mean']:.3f}",
                        'CV Std': f"{results[name]['cv_std']:.3f}",
                        'Score Total': f"{results[name]['accuracy'] + results[name]['f1_score'] + results[name]['cv_mean']:.3f}"
                    })
            
            results_df = pd.DataFrame(results_data)
            
            # Ordenar por score total (acurÃ¡cia + f1 + cv_mean)
            if not results_df.empty:
                results_df = results_df.sort_values('Score Total', ascending=False)
                
                # Mostrar tabela com formataÃ§Ã£o
                st.dataframe(results_df, use_container_width=True)
                
                # GrÃ¡fico de comparaÃ§Ã£o
                fig = px.bar(
                    results_df, 
                    x='Modelo', 
                    y=['AcurÃ¡cia', 'F1-Score', 'CV Mean'],
                    title='ComparaÃ§Ã£o de Performance dos Modelos',
                    barmode='group'
                )
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
                
                # Melhor modelo
                best_model_name = results_df.iloc[0]['Modelo']
                best_model = results[best_model_name]['model']
                best_accuracy = float(results_df.iloc[0]['AcurÃ¡cia'])
                best_score_total = float(results_df.iloc[0]['Score Total'])
                
                st.success(f"ğŸ† **Melhor Modelo:** {best_model_name}")
                st.info(f"ğŸ“Š **AcurÃ¡cia:** {best_accuracy:.3f} | **Score Total:** {best_score_total:.3f}")
                
                # Mostrar top 3 modelos
                st.subheader("ğŸ¥‡ Top 3 Modelos")
                top_3 = results_df.head(3)
                for i, (_, row) in enumerate(top_3.iterrows(), 1):
                    medal = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰"][i-1]
                    st.write(f"{medal} **{row['Modelo']}** - AcurÃ¡cia: {row['AcurÃ¡cia']} | Score: {row['Score Total']}")
                
                # Feature Importance (se disponÃ­vel)
                if hasattr(best_model, 'feature_importances_'):
                    st.subheader("ğŸ¯ ImportÃ¢ncia das Features")
                    
                    feature_importance = pd.DataFrame({
                        'Feature': feature_cols,
                        'Importance': best_model.feature_importances_
                    }).sort_values('Importance', ascending=False)
                    
                    fig = px.bar(feature_importance.head(10), x='Importance', y='Feature', 
                                 title='Top 10 Features Mais Importantes')
                    st.plotly_chart(fig, use_container_width=True)
                
                # Matriz de confusÃ£o
                st.subheader("ğŸ” Matriz de ConfusÃ£o")
                
                y_pred_best = results[best_model_name]['predictions']
                cm = confusion_matrix(y_test, y_pred_best)
                
                fig = px.imshow(cm, 
                                labels=dict(x="Predito", y="Real", color="Quantidade"),
                                x=le_diagnostico.classes_,
                                y=le_diagnostico.classes_,
                                title=f"Matriz de ConfusÃ£o - {best_model_name}")
                st.plotly_chart(fig, use_container_width=True)
                
                # RelatÃ³rio de classificaÃ§Ã£o
                st.subheader("ğŸ“‹ RelatÃ³rio Detalhado")
                report = classification_report(y_test, y_pred_best, target_names=le_diagnostico.classes_, output_dict=True)
                
                report_df = pd.DataFrame(report).transpose()
                st.dataframe(report_df, use_container_width=True)
                
                # SugestÃµes para melhorar acurÃ¡cia
                st.subheader("ğŸ’¡ SugestÃµes para Melhorar AcurÃ¡cia (>85%)")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("""
                    **ğŸ”§ Feature Engineering:**
                    - âœ… Criar mais features derivadas
                    - âœ… Combinar exames laboratoriais
                    - âœ… Agrupar sintomas por severidade
                    - âœ… Usar idade categorizada
                    - âœ… Criar Ã­ndices clÃ­nicos especÃ­ficos
                    """)
                
                with col2:
                    st.markdown("""
                    **ğŸ¤– Modelos AvanÃ§ados:**
                    - âœ… XGBoost com hiperparÃ¢metros otimizados
                    - âœ… Ensemble de mÃºltiplos modelos
                    - âœ… ValidaÃ§Ã£o cruzada estratificada
                    - âœ… Balanceamento de classes
                    - âœ… SeleÃ§Ã£o de features automÃ¡tica
                    """)
                
            else:
                st.error("âŒ Nenhum modelo foi treinado com sucesso!")
    else:
        st.error("âŒ Dataset nÃ£o carregado")

elif pagina == "ğŸ” PrediÃ§Ã£o":
    st.header("ğŸ” PrediÃ§Ã£o Interativa")
    
    if st.session_state.df_main is not None:
        st.info("ğŸ’¡ Use os dados do paciente para fazer prediÃ§Ãµes com o melhor modelo treinado.")
        
        # FormulÃ¡rio para entrada de dados
        with st.form("prediction_form"):
            st.subheader("ğŸ“ Dados do Paciente")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if 'especie' in st.session_state.df_main.columns:
                    especie_pred = st.selectbox("EspÃ©cie:", st.session_state.df_main['especie'].unique())
                if 'sexo' in st.session_state.df_main.columns:
                    sexo_pred = st.selectbox("Sexo:", st.session_state.df_main['sexo'].unique())
                if 'idade_anos' in st.session_state.df_main.columns:
                    idade_pred = st.number_input("Idade (anos):", 0.1, 25.0, 5.0)
            
            with col2:
                if 'hemoglobina' in st.session_state.df_main.columns:
                    hemoglobina_pred = st.number_input("Hemoglobina:", 5.0, 20.0, 12.0)
                if 'hematocrito' in st.session_state.df_main.columns:
                    hematocrito_pred = st.number_input("HematÃ³crito:", 20.0, 60.0, 40.0)
                if 'glicose' in st.session_state.df_main.columns:
                    glicose_pred = st.number_input("Glicose:", 50.0, 300.0, 100.0)
            
            submitted = st.form_submit_button("ğŸ” Predizer DiagnÃ³stico")
            
            if submitted:
                st.success("âœ… PrediÃ§Ã£o realizada! (Em desenvolvimento - use a pÃ¡gina Treinar Modelo primeiro)")
    
    else:
        st.error("âŒ Dataset nÃ£o carregado")

elif pagina == "ğŸ“ˆ EstatÃ­sticas":
    st.header("ğŸ“ˆ EstatÃ­sticas Detalhadas")
    
    if st.session_state.df_main is not None:
        df = st.session_state.df_main
        
        # EstatÃ­sticas gerais
        st.subheader("ğŸ“Š EstatÃ­sticas Gerais")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total de Registros", len(df))
        
        with col2:
            if 'especie' in df.columns:
                st.metric("EspÃ©cies", df['especie'].nunique())
            else:
                st.metric("EspÃ©cies", "N/A")
        
        with col3:
            if 'diagnostico' in df.columns:
                st.metric("DiagnÃ³sticos", df['diagnostico'].nunique())
            else:
                st.metric("DiagnÃ³sticos", "N/A")
        
        with col4:
            st.metric("Colunas", len(df.columns))
        
        # DistribuiÃ§Ã£o por espÃ©cie
        if 'especie' in df.columns:
            st.subheader("ğŸ¾ DistribuiÃ§Ã£o por EspÃ©cie")
            especie_counts = df['especie'].value_counts()
            st.bar_chart(especie_counts)
        
        # DistribuiÃ§Ã£o por diagnÃ³stico
        if 'diagnostico' in df.columns:
            st.subheader("ğŸ¥ DistribuiÃ§Ã£o por DiagnÃ³stico")
            diag_counts = df['diagnostico'].value_counts()
            st.bar_chart(diag_counts)
        
        # Amostra dos dados
        st.subheader("ğŸ“‹ Amostra dos Dados")
        st.dataframe(df.head(10), use_container_width=True)
    
    else:
        st.error("âŒ Dataset nÃ£o carregado")

elif pagina == "ğŸ“ InformaÃ§Ãµes do Dataset":
    st.header("ğŸ“ InformaÃ§Ãµes do Dataset")
    
    if st.session_state.df_main is not None:
        df = st.session_state.df_main
        
        st.subheader("ğŸ“Š Metadados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**Total de registros:** {len(df)}")
            st.write(f"**Total de colunas:** {len(df.columns)}")
            st.write(f"**MemÃ³ria usada:** {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        with col2:
            if hasattr(st.session_state, 'dataset_source'):
                st.write(f"**Fonte do dataset:** {st.session_state.dataset_source}")
            if hasattr(st.session_state, 'dataset_timestamp'):
                st.write(f"**Carregado em:** {st.session_state.dataset_timestamp}")
        
        st.subheader("ğŸ“‹ Estrutura das Colunas")
        
        # InformaÃ§Ãµes sobre cada coluna
        col_info = []
        for col in df.columns:
            col_info.append({
                'Coluna': col,
                'Tipo': str(df[col].dtype),
                'Valores Ãšnicos': df[col].nunique(),
                'Valores Nulos': df[col].isnull().sum(),
                'Valores Nulos %': f"{(df[col].isnull().sum() / len(df)) * 100:.1f}%"
            })
        
        col_info_df = pd.DataFrame(col_info)
        st.dataframe(col_info_df, use_container_width=True)
        
        # Amostra dos dados
        st.subheader("ğŸ“‹ Amostra dos Dados")
        st.dataframe(df.head(20), use_container_width=True)
    
    else:
        st.error("âŒ Dataset nÃ£o carregado")

st.markdown("---")

# Footer
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <p>ğŸ¾ VetDiagnosisAI v1.0 | Desenvolvido para profissionais veterinÃ¡rios e pesquisadores</p>
    <p>âš ï¸ Ferramenta educacional - NÃ£o substitui avaliaÃ§Ã£o clÃ­nica profissional</p>
</div>
""", unsafe_allow_html=True)

