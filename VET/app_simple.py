"""
VetDiagnosisAI - Sistema Inteligente de Apoio ao Diagn√≥stico Veterin√°rio
Vers√£o Simplificada para Deploy
"""

import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="VetDiagnosisAI v2.0 - ML Veterin√°rio Completo",
    page_icon="üêæ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# FOR√áAR ATUALIZA√á√ÉO - VERS√ÉO 2.0
st.info("üöÄ **VET DIAGNOSIS AI v2.0 - SISTEMA ATUALIZADO COM ML COMPLETO!** üöÄ")

# CSS customizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .stAlert {
        margin-top: 1rem;
    }
    .dataset-link {
        padding: 10px;
        background-color: #f0f2f6;
        border-radius: 5px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)

# Header principal
st.markdown('<div class="main-header">üêæ VetDiagnosisAI</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Sistema Inteligente de Apoio ao Diagn√≥stico Veterin√°rio</div>', unsafe_allow_html=True)

# Fun√ß√£o para carregar datasets reais
# @st.cache_data(ttl=60)  # Cache desabilitado para for√ßar atualiza√ß√£o
def carregar_dataset_completo():
    """Carrega o dataset completo da pasta data"""
    try:
        # Tentar carregar datasets da pasta data
        data_path = Path("data")
        csv_files = list(data_path.glob("*.csv")) if data_path.exists() else []
        
        if csv_files:
            # Priorizar datasets espec√≠ficos
            datasets_prioritarios = [
                'veterinary_complete_real_dataset.csv',
                'veterinary_master_dataset.csv', 
                'veterinary_realistic_dataset.csv',
                'clinical_veterinary_data.csv',
                'laboratory_complete_panel.csv'
            ]
            
            dataset_escolhido = None
            
            # Procurar por dataset priorit√°rio
            for dataset in datasets_prioritarios:
                if Path(data_path / dataset).exists():
                    dataset_escolhido = data_path / dataset
                    break
            
            # Se n√£o encontrar priorit√°rio, usar o primeiro dispon√≠vel
            if not dataset_escolhido:
                dataset_escolhido = csv_files[0]
            
            # Carregar o dataset
            df = pd.read_csv(dataset_escolhido)
            
            # Adicionar informa√ß√£o sobre qual dataset foi carregado
            import datetime
            df.attrs['dataset_source'] = dataset_escolhido.name
            df.attrs['dataset_path'] = str(dataset_escolhido)
            df.attrs['load_timestamp'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # Limpar e preparar dados
            df = df.dropna(how='all')  # Remover linhas completamente vazias
            
            # Renomear colunas se necess√°rio
            if 'diagnostico' not in df.columns:
                for col in df.columns:
                    if 'diagnos' in col.lower() or 'outcome' in col.lower():
                        df = df.rename(columns={col: 'diagnostico'})
                        break
            
            # Garantir que temos pelo menos algumas colunas b√°sicas
            colunas_necessarias = ['id', 'especie', 'diagnostico']
            colunas_faltando = [col for col in colunas_necessarias if col not in df.columns]
            
            if colunas_faltando:
                st.warning(f"‚ö†Ô∏è Colunas faltando: {colunas_faltando}")
                
                # Criar colunas b√°sicas se n√£o existirem
                if 'id' not in df.columns:
                    df['id'] = range(1, len(df) + 1)
                if 'especie' not in df.columns:
                    df['especie'] = 'C√£o'  # Default
                if 'diagnostico' not in df.columns:
                    df['diagnostico'] = 'Normal'  # Default
            
            st.success(f"üìä Dataset carregado: {len(df)} registros, {len(df.columns)} colunas")
            return df
        
        else:
            st.warning("‚ö†Ô∏è Nenhum arquivo CSV encontrado na pasta data")
            return gerar_dados_sinteticos()
            
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dataset: {str(e)}")
        st.info("üîÑ Usando dados sint√©ticos como fallback")
        return gerar_dados_sinteticos()

def gerar_dados_sinteticos():
    """Gera dados sint√©ticos como fallback"""
    np.random.seed(42)
    n_samples = 500  # Mais dados sint√©ticos
    
    # Criar dados sint√©ticos mais realistas
    data = {
        'id': range(1, n_samples + 1),
        'especie': np.random.choice(['C√£o', 'Gato', 'Ave', 'Equino'], n_samples, p=[0.5, 0.35, 0.1, 0.05]),
        'raca': np.random.choice(['SRD', 'Pastor Alem√£o', 'Golden Retriever', 'Siames', 'Persa', 'Can√°rio', 'Puro Sangue'], n_samples),
        'idade_anos': np.random.uniform(0.5, 20, n_samples).round(1),
        'sexo': np.random.choice(['M', 'F'], n_samples),
        'peso_kg': np.random.uniform(1, 80, n_samples).round(1),
        
        # Exames laboratoriais completos
        'hemoglobina': np.random.normal(12, 2, n_samples).round(1),
        'hematocrito': np.random.normal(40, 5, n_samples).round(1),
        'leucocitos': np.random.normal(8000, 2000, n_samples).round(0),
        'plaquetas': np.random.normal(300000, 50000, n_samples).round(0),
        'eritrocitos': np.random.normal(6, 1, n_samples).round(2),
        'neutrofilos': np.random.normal(65, 10, n_samples).round(1),
        'linfocitos': np.random.normal(25, 8, n_samples).round(1),
        'monocitos': np.random.normal(5, 2, n_samples).round(1),
        'eosinofilos': np.random.normal(3, 1.5, n_samples).round(1),
        
        # Bioqu√≠mica
        'glicose': np.random.normal(100, 20, n_samples).round(1),
        'ureia': np.random.normal(30, 10, n_samples).round(1),
        'creatinina': np.random.normal(1.2, 0.3, n_samples).round(2),
        'alt': np.random.normal(40, 15, n_samples).round(1),
        'ast': np.random.normal(35, 12, n_samples).round(1),
        'fosfatase_alcalina': np.random.normal(120, 30, n_samples).round(1),
        'fa': np.random.normal(80, 20, n_samples).round(1),
        'ggt': np.random.normal(25, 10, n_samples).round(1),
        'proteinas_totais': np.random.normal(6.5, 1, n_samples).round(1),
        'albumina': np.random.normal(3.5, 0.5, n_samples).round(1),
        'globulinas': np.random.normal(3.0, 0.8, n_samples).round(1),
        'colesterol': np.random.normal(180, 40, n_samples).round(1),
        'triglicerideos': np.random.normal(100, 30, n_samples).round(1),
        'bilirrubina_total': np.random.normal(0.5, 0.2, n_samples).round(2),
        'calcio': np.random.normal(10, 1, n_samples).round(1),
        'fosforo': np.random.normal(4.5, 1, n_samples).round(1),
        'sodio': np.random.normal(145, 5, n_samples).round(1),
        'potassio': np.random.normal(4.5, 0.5, n_samples).round(1),
        
        # Sinais vitais
        'temperatura_retal': np.random.normal(38.5, 0.5, n_samples).round(1),
        'pulso': np.random.normal(120, 20, n_samples).round(0),
        'freq_respiratoria': np.random.normal(20, 5, n_samples).round(0),
        
        # Sintomas (0 = n√£o, 1 = sim)
        'febre': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),
        'apatia': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),
        'perda_peso': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),
        'vomito': np.random.choice([0, 1], n_samples, p=[0.75, 0.25]),
        'diarreia': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),
        'tosse': np.random.choice([0, 1], n_samples, p=[0.85, 0.15]),
        'letargia': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),
        'feridas_cutaneas': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),
        'poliuria': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),
        'polidipsia': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),
        'dor': np.random.choice([0, 1], n_samples, p=[0.85, 0.15]),
        'cirurgia': np.random.choice([0, 1], n_samples, p=[0.95, 0.05]),
        
        # Diagn√≥stico mais realista
        'diagnostico': np.random.choice([
            'Normal', 'Infec√ß√£o Respirat√≥ria', 'Doen√ßa Renal', 'Diabetes', 
            'Problema Gastrointestinal', 'Dermatite', 'Doen√ßa Hep√°tica',
            'Anemia', 'Leucemia', 'Insufici√™ncia Card√≠aca', 'Tumor',
            'Parasitose', 'Alergia', 'Fratura', 'Doen√ßa Infecciosa'
        ], n_samples, p=[0.3, 0.12, 0.08, 0.08, 0.08, 0.06, 0.05, 0.05, 0.03, 0.03, 0.03, 0.04, 0.03, 0.02, 0.02])
    }
    
    df = pd.DataFrame(data)
    return df

# CARREGAR DADOS REAIS DIRETAMENTE - SEMPRE!
st.info("üîÑ **VERS√ÉO 2.0 - CARREGANDO DADOS REAIS COM ML COMPLETO...**")

# Tentar carregar datasets reais diretamente
data_path = Path("data")
df = None
dataset_carregado = None

# Lista de datasets reais em ordem de prioridade
real_datasets = [
    'veterinary_complete_real_dataset.csv',  # 800 registros
    'clinical_veterinary_data.csv',          # 500 registros
    'veterinary_master_dataset.csv',         # 500 registros
    'veterinary_realistic_dataset.csv',      # 1280 registros
    'laboratory_complete_panel.csv',         # 300 registros
    'uci_horse_colic.csv',                   # 368 registros
    'exemplo_vet.csv'                        # 300 registros (fallback)
]

# Tentar carregar cada dataset at√© encontrar um
for dataset_name in real_datasets:
    dataset_path = data_path / dataset_name
    if dataset_path.exists():
        try:
            df = pd.read_csv(dataset_path)
            dataset_carregado = dataset_name
            st.success(f"‚úÖ Dataset carregado: {dataset_name} ({len(df)} registros)")
            break
        except Exception as e:
            st.error(f"‚ùå Erro ao carregar {dataset_name}: {e}")
            continue

# Se n√£o conseguiu carregar nenhum dataset real, usar fun√ß√£o de fallback
if df is None or len(df) == 0:
    st.warning("‚ö†Ô∏è N√£o foi poss√≠vel carregar datasets reais. Usando fun√ß√£o de fallback...")
    df = carregar_dataset_completo()
    dataset_carregado = "fallback"

# Verificar se os dados foram carregados
if df is None or len(df) == 0:
    st.error("‚ùå Erro cr√≠tico: N√£o foi poss√≠vel carregar nenhum dataset!")
    st.stop()

# Adicionar informa√ß√µes de debug
df.attrs = {
    'dataset_source': dataset_carregado,
    'dataset_path': str(data_path / dataset_carregado) if dataset_carregado != "fallback" else "fallback",
    'load_timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
}

# Sidebar
with st.sidebar:
    st.image("https://img.icons8.com/color/96/000000/veterinarian.png", width=100)
    st.title("üêæ VetDiagnosisAI")
    st.markdown("---")
    
    st.subheader("üìä Status dos Dados")
    st.success(f"‚úÖ Dataset carregado: {len(df)} registros")
    st.info(f"üìÖ Colunas: {len(df.columns)}")
    
    # Mostrar status do dataset carregado
    if len(df) >= 500:
        st.success(f"üéâ Dataset real carregado! ({len(df)} registros)")
    elif len(df) >= 300:
        st.warning(f"‚ö†Ô∏è Dataset m√©dio carregado ({len(df)} registros)")
    else:
        st.error(f"‚ùå Dataset pequeno detectado ({len(df)} registros)")
        
    # Mostrar informa√ß√µes b√°sicas sobre arquivos dispon√≠veis
    data_path = Path("data")
    if data_path.exists():
        csv_files = list(data_path.glob("*.csv"))
        st.info(f"üìÅ {len(csv_files)} arquivos CSV dispon√≠veis")
    else:
        st.error("‚ùå Pasta 'data' n√£o encontrada!")
    
    # Mostrar informa√ß√µes de debug sobre o dataset
    if hasattr(df, 'attrs') and 'dataset_source' in df.attrs:
        st.success(f"üìÅ Dataset: {df.attrs['dataset_source']}")
        st.caption(f"üîó Caminho: {df.attrs['dataset_path']}")
        if 'load_timestamp' in df.attrs:
            st.caption(f"‚è∞ Carregado em: {df.attrs['load_timestamp']}")
    else:
        st.warning("‚ö†Ô∏è Informa√ß√µes do dataset n√£o dispon√≠veis")
    
    # Verificar se as colunas existem antes de acess√°-las
    if 'especie' in df.columns:
        st.info(f"üêæ Esp√©cies: {df['especie'].nunique()}")
    if 'diagnostico' in df.columns:
        st.info(f"üè• Diagn√≥sticos: {df['diagnostico'].nunique()}")
    
    # Mostrar informa√ß√µes sobre o dataset
    if hasattr(df, 'name') or 'veterinary' in str(df.columns):
        st.success("üìÅ Dataset real carregado")
    else:
        st.info("üîÑ Usando dados sint√©ticos")
    
    # Bot√£o para for√ßar reload
    st.markdown("---")
    if st.button("üîÑ For√ßar Reload dos Dados", use_container_width=True):
        carregar_dataset_completo.clear()
        st.rerun()
    
    # Mostrar primeiras colunas
    st.write("**Colunas principais:**")
    colunas_principais = [col for col in df.columns[:10]]
    for col in colunas_principais:
        st.write(f"‚Ä¢ {col}")
    
    if len(df.columns) > 10:
        st.write(f"... e mais {len(df.columns) - 10} colunas")
    
    st.markdown("---")
    
    # Bot√£o para recarregar dados
    if st.button("üîÑ Recarregar Dataset"):
        st.cache_data.clear()
        st.rerun()
    
    st.markdown("---")
    
    st.subheader("üìã Navega√ß√£o")
    pagina = st.selectbox(
        "Escolha uma p√°gina:",
        [
            "üè† Vis√£o Geral",
            "üìä An√°lise de Dados", 
            "ü§ñ Predi√ß√£o de Diagn√≥stico",
            "üìà Estat√≠sticas",
            "üìÅ Informa√ß√µes do Dataset"
        ]
    )

# Conte√∫do principal baseado na p√°gina selecionada
if pagina == "üè† Vis√£o Geral":
    st.header("üè† Vis√£o Geral do Sistema")
    
    # M√©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìä Total de Registros", len(df))
    
    with col2:
        if 'especie' in df.columns:
            st.metric("üêæ Esp√©cies √önicas", df['especie'].nunique())
        else:
            st.metric("üêæ Esp√©cies √önicas", "N/A")
    
    with col3:
        if 'diagnostico' in df.columns:
            st.metric("üè• Diagn√≥sticos √önicos", df['diagnostico'].nunique())
        else:
            st.metric("üè• Diagn√≥sticos √önicos", "N/A")
    
    with col4:
        st.metric("üî¨ Exames Dispon√≠veis", len([col for col in df.columns if col not in ['id', 'especie', 'raca', 'diagnostico']]))
    
    st.markdown("---")
    
    # Distribui√ß√µes com mais detalhes
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üêæ Distribui√ß√£o por Esp√©cie")
        if 'especie' in df.columns:
            especie_counts = df['especie'].value_counts()
        else:
            especie_counts = pd.Series()
        
        # Mostrar contagens
        st.write("**Contagens:**")
        for especie, count in especie_counts.items():
            percentage = (count / len(df)) * 100
            st.write(f"‚Ä¢ {especie}: {count} ({percentage:.1f}%)")
        
        # Gr√°fico
        st.bar_chart(especie_counts)
    
    with col2:
        st.subheader("üè• Distribui√ß√£o de Diagn√≥sticos")
        if 'diagnostico' in df.columns:
            diag_counts = df['diagnostico'].value_counts()
        else:
            diag_counts = pd.Series()
        
        # Mostrar contagens
        st.write("**Top 5 Diagn√≥sticos:**")
        for diag, count in diag_counts.head().items():
            percentage = (count / len(df)) * 100
            st.write(f"‚Ä¢ {diag}: {count} ({percentage:.1f}%)")
        
        # Gr√°fico
        st.bar_chart(diag_counts)
    
    st.markdown("---")
    
    # Estat√≠sticas adicionais
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Estat√≠sticas de Idade")
        if 'idade_anos' in df.columns:
            idade_stats = df['idade_anos'].describe()
        else:
            idade_stats = pd.Series()
        if not idade_stats.empty:
            st.write(f"**Idade M√©dia:** {idade_stats['mean']:.1f} anos")
            st.write(f"**Idade M√≠nima:** {idade_stats['min']:.1f} anos")
            st.write(f"**Idade M√°xima:** {idade_stats['max']:.1f} anos")
            
            # Histograma de idade
            st.bar_chart(df['idade_anos'].value_counts().sort_index())
        else:
            st.info("‚ÑπÔ∏è Informa√ß√µes de idade n√£o dispon√≠veis")
    
    with col2:
        st.subheader("üå°Ô∏è Sinais Vitais M√©dios")
        
        # Verificar se as colunas existem antes de acess√°-las
        if 'temperatura_retal' in df.columns:
            temp_media = df['temperatura_retal'].mean()
            st.write(f"**Temperatura M√©dia:** {temp_media:.1f}¬∞C")
        
        if 'pulso' in df.columns:
            pulso_medio = df['pulso'].mean()
            st.write(f"**Pulso M√©dio:** {pulso_medio:.0f} bpm")
        
        if 'freq_respiratoria' in df.columns:
            freq_media = df['freq_respiratoria'].mean()
            st.write(f"**Frequ√™ncia Respirat√≥ria:** {freq_media:.0f} rpm")
        
        # Se nenhuma coluna de sinais vitais existir, mostrar outras m√©tricas
        if not any(col in df.columns for col in ['temperatura_retal', 'pulso', 'freq_respiratoria']):
            st.info("‚ÑπÔ∏è Sinais vitais n√£o dispon√≠veis neste dataset")
        
        # Gr√°fico de temperatura por esp√©cie (se dispon√≠vel)
        if 'temperatura_retal' in df.columns and 'especie' in df.columns:
            temp_por_especie = df.groupby('especie')['temperatura_retal'].mean()
            st.bar_chart(temp_por_especie)
    
    st.markdown("---")
    
    # Amostra dos dados com mais informa√ß√µes
    st.subheader("üìã Amostra dos Dados (Primeiros 10 Registros)")
    
    # Selecionar colunas principais para exibir
    colunas_principais = ['id', 'especie', 'raca', 'idade_anos', 'sexo', 'diagnostico', 
                         'temperatura_retal', 'febre', 'vomito', 'diarreia']
    
    if all(col in df.columns for col in colunas_principais):
        st.dataframe(df[colunas_principais].head(10), use_container_width=True)
    else:
        st.dataframe(df.head(10), use_container_width=True)
    
    # Informa√ß√µes sobre o dataset
    st.markdown("---")
    st.subheader("‚ÑπÔ∏è Informa√ß√µes sobre o Dataset")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Colunas Dispon√≠veis:**")
        st.write(f"Total: {len(df.columns)} colunas")
        st.write("‚Ä¢ Identifica√ß√£o: id, esp√©cie, ra√ßa, idade, sexo")
        st.write("‚Ä¢ Exames: hemoglobina, hemat√≥crito, leuc√≥citos, etc.")
        st.write("‚Ä¢ Sinais vitais: temperatura, pulso, frequ√™ncia respirat√≥ria")
        st.write("‚Ä¢ Sintomas: febre, v√¥mito, diarreia, apatia, etc.")
        st.write("‚Ä¢ Diagn√≥stico: classifica√ß√£o da condi√ß√£o")
    
    with col2:
        st.write("**Qualidade dos Dados:**")
        valores_nulos = df.isnull().sum().sum()
        st.write(f"‚Ä¢ Registros sem dados faltantes: {len(df) - valores_nulos}/{len(df)}")
        if 'especie' in df.columns:
            st.write(f"‚Ä¢ Esp√©cies: {', '.join(df['especie'].unique())}")
        if 'idade_anos' in df.columns:
            st.write(f"‚Ä¢ Faixa de idade: {df['idade_anos'].min():.1f} - {df['idade_anos'].max():.1f} anos")
        st.write(f"‚Ä¢ Dados sint√©ticos para demonstra√ß√£o")

elif pagina == "üìä An√°lise de Dados":
    st.header("üìä An√°lise Explorat√≥ria dos Dados")
    
    # Filtros
    st.subheader("üîç Filtros")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if 'especie' in df.columns:
            especie_filtro = st.selectbox("Esp√©cie:", ['Todas'] + list(df['especie'].unique()))
        else:
            especie_filtro = 'Todas'
    
    with col2:
        idade_min, idade_max = st.slider("Faixa de Idade:", 0.0, 20.0, (0.0, 20.0))
    
    with col3:
        if 'diagnostico' in df.columns:
            diag_filtro = st.selectbox("Diagn√≥stico:", ['Todos'] + list(df['diagnostico'].unique()))
        else:
            diag_filtro = 'Todos'
    
    # Aplicar filtros
    df_filtrado = df.copy()
    if especie_filtro != 'Todas':
        df_filtrado = df_filtrado[df_filtrado['especie'] == especie_filtro]
    
    df_filtrado = df_filtrado[
        (df_filtrado['idade_anos'] >= idade_min) & 
        (df_filtrado['idade_anos'] <= idade_max)
    ]
    
    if diag_filtro != 'Todos':
        df_filtrado = df_filtrado[df_filtrado['diagnostico'] == diag_filtro]
    
    st.info(f"üìä Mostrando {len(df_filtrado)} registros ap√≥s filtros")
    
    # An√°lises
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìà Exames Laboratoriais")
        
        exames = ['hemoglobina', 'hematocrito', 'leucocitos', 'glicose', 'ureia', 'creatinina']
        exame_selecionado = st.selectbox("Selecione um exame:", exames)
        
        # Box plot do exame selecionado
        st.bar_chart(df_filtrado.groupby('diagnostico')[exame_selecionado].mean())
    
    with col2:
        st.subheader("üå°Ô∏è Sinais Vitais")
        
        sinais = ['temperatura_retal', 'pulso', 'freq_respiratoria']
        sinal_selecionado = st.selectbox("Selecione um sinal vital:", sinais)
        
        st.bar_chart(df_filtrado.groupby('diagnostico')[sinal_selecionado].mean())
    
    # Correla√ß√µes
    st.subheader("üîó Correla√ß√µes entre Vari√°veis")
    
    # Selecionar colunas num√©ricas para correla√ß√£o
    colunas_numericas = df_filtrado.select_dtypes(include=[np.number]).columns.tolist()
    if len(colunas_numericas) > 1:
        correlacao = df_filtrado[colunas_numericas].corr()
        st.dataframe(correlacao)

elif pagina == "ü§ñ Predi√ß√£o de Diagn√≥stico":
    st.header("ü§ñ Sistema de Machine Learning Veterin√°rio v2.0")
    st.success("üéâ **ATUALIZADO!** Sistema completo de ML com feature engineering avan√ßado!")
    
    # Verificar se temos dados suficientes para ML
    if 'diagnostico' not in df.columns:
        st.error("‚ùå Coluna 'diagnostico' n√£o encontrada. N√£o √© poss√≠vel treinar modelos.")
        st.stop()
    
    # Preparar dados para ML
    st.subheader("üîß Prepara√ß√£o dos Dados")
    
    # Feature Engineering Avan√ßado
    df_ml = df.copy()
    
    # 1. Codifica√ß√£o de vari√°veis categ√≥ricas
    from sklearn.preprocessing import LabelEncoder, StandardScaler
    le_especie = LabelEncoder()
    le_sexo = LabelEncoder()
    le_diagnostico = LabelEncoder()
    
    if 'especie' in df_ml.columns:
        df_ml['especie_encoded'] = le_especie.fit_transform(df_ml['especie'])
    if 'sexo' in df_ml.columns:
        df_ml['sexo_encoded'] = le_sexo.fit_transform(df_ml['sexo'])
    
    df_ml['diagnostico_encoded'] = le_diagnostico.fit_transform(df_ml['diagnostico'])
    
    # 2. Criar features derivadas
    if 'idade_anos' in df_ml.columns:
        df_ml['idade_categoria'] = pd.cut(df_ml['idade_anos'], bins=[0, 2, 7, 15, 100], labels=['Filhote', 'Adulto Jovem', 'Adulto', 'Idoso'])
        df_ml['idade_categoria_encoded'] = LabelEncoder().fit_transform(df_ml['idade_categoria'])
    
    # 3. Features de exames laboratoriais combinados
    exames_cols = ['hemoglobina', 'hematocrito', 'leucocitos', 'glicose', 'ureia', 'creatinina']
    exames_disponiveis = [col for col in exames_cols if col in df_ml.columns]
    
    if len(exames_disponiveis) >= 2:
        # Criar √≠ndices combinados
        if 'hemoglobina' in df_ml.columns and 'hematocrito' in df_ml.columns:
            df_ml['indice_anemia'] = df_ml['hemoglobina'] / df_ml['hematocrito']
        if 'ureia' in df_ml.columns and 'creatinina' in df_ml.columns:
            df_ml['indice_renal'] = df_ml['ureia'] / df_ml['creatinina']
    
    # 4. Features de sintomas combinados
    sintomas_cols = ['febre', 'apatia', 'perda_peso', 'vomito', 'diarreia', 'tosse', 'letargia']
    sintomas_disponiveis = [col for col in sintomas_cols if col in df_ml.columns]
    
    if len(sintomas_disponiveis) >= 2:
        df_ml['total_sintomas'] = df_ml[sintomas_disponiveis].sum(axis=1)
        df_ml['severidade_sintomas'] = pd.cut(df_ml['total_sintomas'], bins=[-1, 0, 2, 4, 10], labels=['Assintom√°tico', 'Leve', 'Moderado', 'Severo'])
        df_ml['severidade_sintomas_encoded'] = LabelEncoder().fit_transform(df_ml['severidade_sintomas'])
    
    # Selecionar features para ML
    feature_cols = []
    
    # Adicionar colunas num√©ricas originais
    numeric_cols = df_ml.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols.extend([col for col in numeric_cols if col not in ['diagnostico_encoded']])
    
    # Remover colunas com muitos valores √∫nicos (como ID)
    feature_cols = [col for col in feature_cols if df_ml[col].nunique() < len(df_ml) * 0.8]
    
    X = df_ml[feature_cols].fillna(df_ml[feature_cols].mean())
    y = df_ml['diagnostico_encoded']
    
    st.success(f"‚úÖ Dados preparados: {X.shape[0]} amostras, {X.shape[1]} features")
    
    # Dividir dados
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # Escalar features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    st.info(f"üìä Divis√£o dos dados: {X_train.shape[0]} treino, {X_test.shape[0]} teste")
    
    # Treinar m√∫ltiplos modelos
    st.subheader("ü§ñ Treinamento de Modelos")
    
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
    import plotly.express as px
    import plotly.graph_objects as go
    
    models = {
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'Gradient Boosting': GradientBoostingClassifier(random_state=42),
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
        'SVM': SVC(random_state=42, probability=True),
        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)
    }
    
    results = {}
    
    for name, model in models.items():
        with st.spinner(f"Treinando {name}..."):
            model.fit(X_train_scaled, y_train)
            y_pred = model.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)
            results[name] = {
                'model': model,
                'accuracy': accuracy,
                'predictions': y_pred
            }
    
    # Mostrar resultados
    st.subheader("üìä Resultados dos Modelos")
    
    # Tabela de resultados
    results_df = pd.DataFrame({
        'Modelo': list(results.keys()),
        'Acur√°cia': [results[name]['accuracy'] for name in results.keys()]
    }).sort_values('Acur√°cia', ascending=False)
    
    st.dataframe(results_df, use_container_width=True)
    
    # Melhor modelo
    best_model_name = results_df.iloc[0]['Modelo']
    best_model = results[best_model_name]['model']
    best_accuracy = results_df.iloc[0]['Acur√°cia']
    
    st.success(f"üèÜ **Melhor Modelo:** {best_model_name} com {best_accuracy:.3f} de acur√°cia")
    
    # Feature Importance (se dispon√≠vel)
    if hasattr(best_model, 'feature_importances_'):
        st.subheader("üéØ Import√¢ncia das Features")
        
        feature_importance = pd.DataFrame({
            'Feature': feature_cols,
            'Importance': best_model.feature_importances_
        }).sort_values('Importance', ascending=False)
        
        fig = px.bar(feature_importance.head(10), x='Importance', y='Feature', 
                     title='Top 10 Features Mais Importantes')
        st.plotly_chart(fig, use_container_width=True)
    
    # Matriz de confus√£o
    st.subheader("üîç Matriz de Confus√£o")
    
    y_pred_best = results[best_model_name]['predictions']
    cm = confusion_matrix(y_test, y_pred_best)
    
    fig = px.imshow(cm, 
                    labels=dict(x="Predito", y="Real", color="Quantidade"),
                    x=le_diagnostico.classes_,
                    y=le_diagnostico.classes_,
                    title=f"Matriz de Confus√£o - {best_model_name}")
    st.plotly_chart(fig, use_container_width=True)
    
    # Relat√≥rio de classifica√ß√£o
    st.subheader("üìã Relat√≥rio Detalhado")
    report = classification_report(y_test, y_pred_best, target_names=le_diagnostico.classes_, output_dict=True)
    
    report_df = pd.DataFrame(report).transpose()
    st.dataframe(report_df, use_container_width=True)
    
    # Sugest√µes para melhorar acur√°cia
    st.subheader("üí° Sugest√µes para Melhorar Acur√°cia (>85%)")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        **üîß Feature Engineering:**
        - ‚úÖ Criar mais features derivadas
        - ‚úÖ Combinar exames laboratoriais
        - ‚úÖ Agrupar sintomas por severidade
        - ‚úÖ Usar idade categorizada
        - ‚úÖ Criar √≠ndices cl√≠nicos espec√≠ficos
        """)
    
    with col2:
        st.markdown("""
        **ü§ñ Modelos Avan√ßados:**
        - ‚úÖ XGBoost com hiperpar√¢metros otimizados
        - ‚úÖ Ensemble de m√∫ltiplos modelos
        - ‚úÖ Valida√ß√£o cruzada estratificada
        - ‚úÖ Balanceamento de classes
        - ‚úÖ Sele√ß√£o de features autom√°tica
        """)
    
    # Predi√ß√£o interativa
    st.subheader("üîÆ Predi√ß√£o Interativa")
    
    with st.form("prediction_form"):
        st.markdown("**Insira os dados do paciente para predi√ß√£o:**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if 'especie' in df.columns:
                especie_pred = st.selectbox("Esp√©cie:", df['especie'].unique())
            if 'sexo' in df.columns:
                sexo_pred = st.selectbox("Sexo:", df['sexo'].unique())
            if 'idade_anos' in df.columns:
                idade_pred = st.number_input("Idade (anos):", 0.1, 25.0, 5.0)
        
        with col2:
            if 'hemoglobina' in df.columns:
                hemoglobina_pred = st.number_input("Hemoglobina:", 5.0, 20.0, 12.0)
            if 'hematocrito' in df.columns:
                hematocrito_pred = st.number_input("Hemat√≥crito:", 20.0, 60.0, 40.0)
            if 'glicose' in df.columns:
                glicose_pred = st.number_input("Glicose:", 50.0, 300.0, 100.0)
        
        submitted = st.form_submit_button("üîç Predizer Diagn√≥stico")
        
        if submitted:
            # Preparar dados para predi√ß√£o
            pred_data = {}
            
            for col in feature_cols:
                if col == 'especie_encoded' and 'especie' in df.columns:
                    pred_data[col] = le_especie.transform([especie_pred])[0]
                elif col == 'sexo_encoded' and 'sexo' in df.columns:
                    pred_data[col] = le_sexo.transform([sexo_pred])[0]
                elif col == 'idade_anos':
                    pred_data[col] = idade_pred
                elif col == 'hemoglobina':
                    pred_data[col] = hemoglobina_pred
                elif col == 'hematocrito':
                    pred_data[col] = hematocrito_pred
                elif col == 'glicose':
                    pred_data[col] = glicose_pred
                else:
                    # Usar valor m√©dio para features n√£o especificadas
                    pred_data[col] = X[col].mean()
            
            # Converter para DataFrame e escalar
            pred_df = pd.DataFrame([pred_data])
            pred_scaled = scaler.transform(pred_df)
            
            # Fazer predi√ß√£o
            prediction = best_model.predict(pred_scaled)[0]
            prediction_proba = best_model.predict_proba(pred_scaled)[0]
            
            # Mostrar resultado
            diagnostico_predito = le_diagnostico.inverse_transform([prediction])[0]
            confianca = prediction_proba.max()
            
            st.success(f"üéØ **Diagn√≥stico Predito:** {diagnostico_predito}")
            st.info(f"üìä **Confian√ßa:** {confianca:.2%}")
            
            # Mostrar probabilidades de todos os diagn√≥sticos
            proba_df = pd.DataFrame({
                'Diagn√≥stico': le_diagnostico.classes_,
                'Probabilidade': prediction_proba
            }).sort_values('Probabilidade', ascending=False)
            
            st.subheader("üìà Probabilidades de Todos os Diagn√≥sticos")
            st.dataframe(proba_df, use_container_width=True)
            
            # Gr√°fico de probabilidades
            fig = px.bar(proba_df, x='Probabilidade', y='Diagn√≥stico', 
                        title='Probabilidades de Diagn√≥stico')
            st.plotly_chart(fig, use_container_width=True)

elif pagina == "üìà Estat√≠sticas":
    st.header("üìà Estat√≠sticas Detalhadas")
    
    # Estat√≠sticas gerais
    st.subheader("üìä Estat√≠sticas Gerais")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üë∂ M√©dia de Idade", f"{df['idade_anos'].mean():.1f} anos")
        st.metric("‚öñÔ∏è Peso M√©dio", f"{df['peso_kg'].mean():.1f} kg")
        st.metric("üå°Ô∏è Temperatura M√©dia", f"{df['temperatura_retal'].mean():.1f}¬∞C")
    
    with col2:
        st.metric("üî• Taxa de Febre", f"{(df['febre'].sum() / len(df) * 100):.1f}%")
        st.metric("ü§Æ Taxa de V√¥mito", f"{(df['vomito'].sum() / len(df) * 100):.1f}%")
        st.metric("üí© Taxa de Diarreia", f"{(df['diarreia'].sum() / len(df) * 100):.1f}%")
    
    with col3:
        st.metric("üò¥ Taxa de Apatia", f"{(df['apatia'].sum() / len(df) * 100):.1f}%")
        st.metric("üìâ Taxa de Perda de Peso", f"{(df['perda_peso'].sum() / len(df) * 100):.1f}%")
        st.metric("ü´Å Taxa de Tosse", f"{(df['tosse'].sum() / len(df) * 100):.1f}%")
    
    st.markdown("---")
    
    # An√°lises por esp√©cie
    st.subheader("üêæ An√°lises por Esp√©cie")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Estat√≠sticas por Esp√©cie")
        especie_stats = df.groupby('especie').agg({
            'idade_anos': ['mean', 'std'],
            'peso_kg': ['mean', 'std'],
            'temperatura_retal': ['mean', 'std'],
            'febre': 'sum',
            'vomito': 'sum',
            'diarreia': 'sum'
        }).round(2)
        
        # Simplificar nomes das colunas
        especie_stats.columns = ['Idade_M√©dia', 'Idade_Desvio', 'Peso_M√©dio', 'Peso_Desvio',
                               'Temp_M√©dia', 'Temp_Desvio', 'Casos_Febre', 'Casos_V√¥mito', 'Casos_Diarreia']
        st.dataframe(especie_stats)
    
    with col2:
        st.subheader("üìà Distribui√ß√£o de Idades por Esp√©cie")
        # Criar histograma de idades por esp√©cie
        for especie in df['especie'].unique():
            especie_data = df[df['especie'] == especie]['idade_anos']
            st.write(f"**{especie}** - Idades:")
            st.bar_chart(especie_data.value_counts().sort_index())
    
    st.markdown("---")
    
    # An√°lises por diagn√≥stico
    st.subheader("üè• An√°lises por Diagn√≥stico")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Estat√≠sticas por Diagn√≥stico")
        diag_stats = df.groupby('diagnostico').agg({
            'idade_anos': ['mean', 'count'],
            'peso_kg': 'mean',
            'temperatura_retal': 'mean',
            'febre': 'mean',
            'vomito': 'mean'
        }).round(2)
        
        diag_stats.columns = ['Idade_M√©dia', 'N_Casos', 'Peso_M√©dio', 'Temp_M√©dia', 'Taxa_Febre', 'Taxa_V√¥mito']
        st.dataframe(diag_stats.sort_values('N_Casos', ascending=False))
    
    with col2:
        st.subheader("üìà Distribui√ß√£o de Diagn√≥sticos")
        diag_counts = df.groupby('diagnostico').size().sort_values(ascending=False)
        st.bar_chart(diag_counts)
        
        # Mostrar percentuais
        st.write("**Percentuais:**")
        total = len(df)
        for diag, count in diag_counts.items():
            percentage = (count / total) * 100
            st.write(f"‚Ä¢ {diag}: {percentage:.1f}%")
    
    st.markdown("---")
    
    # Exames laboratoriais
    st.subheader("üî¨ An√°lise de Exames Laboratoriais")
    
    exames_cols = ['hemoglobina', 'hematocrito', 'leucocitos', 'glicose', 'ureia', 'creatinina']
    exames_disponiveis = [col for col in exames_cols if col in df.columns]
    
    if exames_disponiveis:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä Estat√≠sticas dos Exames")
            exames_stats = df[exames_disponiveis].describe().round(2)
            st.dataframe(exames_stats)
        
        with col2:
            st.subheader("üìà Exame Selecionado por Diagn√≥stico")
            exame_selecionado = st.selectbox("Selecione um exame:", exames_disponiveis)
            
            exame_por_diag = df.groupby('diagnostico')[exame_selecionado].mean().sort_values(ascending=False)
            st.bar_chart(exame_por_diag)
            
            st.write(f"**M√©dia geral de {exame_selecionado}:** {df[exame_selecionado].mean():.2f}")
    
    st.markdown("---")
    
    # Correla√ß√µes
    st.subheader("üîó Matriz de Correla√ß√µes")
    
    colunas_numericas = df.select_dtypes(include=[np.number]).columns.tolist()
    if len(colunas_numericas) > 1:
        correlacao = df[colunas_numericas].corr()
        
        # Mostrar apenas correla√ß√µes relevantes
        st.write("**Correla√ß√µes mais significativas:**")
        for i in range(len(correlacao.columns)):
            for j in range(i+1, len(correlacao.columns)):
                corr_val = correlacao.iloc[i, j]
                if abs(corr_val) > 0.3:  # Apenas correla√ß√µes moderadas/fortes
                    st.write(f"‚Ä¢ {correlacao.columns[i]} ‚Üî {correlacao.columns[j]}: {corr_val:.3f}")
    
    st.markdown("---")
    
    # Download dos dados
    st.subheader("üì• Download de Dados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üìä Baixar Dataset Completo (CSV)",
            data=csv,
            file_name='veterinary_data_complete.csv',
            mime='text/csv',
        )
    
    with col2:
        # Estat√≠sticas resumidas
        resumo_stats = df.describe().round(2)
        csv_resumo = resumo_stats.to_csv().encode('utf-8')
        st.download_button(
            label="üìà Baixar Estat√≠sticas Resumidas (CSV)",
            data=csv_resumo,
            file_name='veterinary_statistics.csv',
            mime='text/csv',
        )

elif pagina == "üìÅ Informa√ß√µes do Dataset":
    st.header("üìÅ Informa√ß√µes Detalhadas do Dataset")
    
    # Informa√ß√µes gerais
    st.subheader("üìä Resumo Geral")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìÑ Total de Registros", len(df))
    
    with col2:
        st.metric("üìã Total de Colunas", len(df.columns))
    
    with col3:
        valores_nulos = df.isnull().sum().sum()
        st.metric("‚ùå Valores Nulos", valores_nulos)
    
    with col4:
        memoria_mb = df.memory_usage(deep=True).sum() / 1024 / 1024
        st.metric("üíæ Mem√≥ria (MB)", f"{memoria_mb:.2f}")
    
    st.markdown("---")
    
    # Informa√ß√µes sobre colunas
    st.subheader("üìã Estrutura das Colunas")
    
    # An√°lise por tipo de coluna
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üî¢ Colunas Num√©ricas")
        colunas_numericas = df.select_dtypes(include=[np.number]).columns.tolist()
        st.write(f"**Total:** {len(colunas_numericas)} colunas")
        for col in colunas_numericas:
            st.write(f"‚Ä¢ {col}")
    
    with col2:
        st.subheader("üìù Colunas Categ√≥ricas")
        colunas_categoricas = df.select_dtypes(include=['object']).columns.tolist()
        st.write(f"**Total:** {len(colunas_categoricas)} colunas")
        for col in colunas_categoricas:
            st.write(f"‚Ä¢ {col}")
    
    st.markdown("---")
    
    # Estat√≠sticas descritivas
    st.subheader("üìà Estat√≠sticas Descritivas")
    
    if len(colunas_numericas) > 0:
        st.dataframe(df[colunas_numericas].describe().round(2), use_container_width=True)
    else:
        st.info("Nenhuma coluna num√©rica encontrada")
    
    st.markdown("---")
    
    # Valores √∫nicos por coluna
    st.subheader("üîç Valores √önicos por Coluna")
    
    valores_unicos = []
    for col in df.columns:
        n_unicos = df[col].nunique()
        valores_unicos.append({
            'Coluna': col,
            'Valores √önicos': n_unicos,
            'Tipo': str(df[col].dtype),
            'Valores Nulos': df[col].isnull().sum()
        })
    
    df_unicos = pd.DataFrame(valores_unicos)
    st.dataframe(df_unicos, use_container_width=True)
    
    st.markdown("---")
    
    # Amostra dos dados
    st.subheader("üëÄ Amostra dos Dados")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Primeiros 5 registros:**")
        st.dataframe(df.head(), use_container_width=True)
    
    with col2:
        st.write("**√öltimos 5 registros:**")
        st.dataframe(df.tail(), use_container_width=True)
    
    st.markdown("---")
    
    # Informa√ß√µes sobre o arquivo
    st.subheader("üìÅ Informa√ß√µes do Arquivo")
    
    # Tentar identificar o arquivo carregado
    try:
        data_path = Path("data")
        if data_path.exists():
            csv_files = list(data_path.glob("*.csv"))
            
            st.write("**Arquivos CSV dispon√≠veis na pasta data:**")
            for i, arquivo in enumerate(csv_files, 1):
                tamanho = arquivo.stat().st_size / 1024  # KB
                st.write(f"{i}. {arquivo.name} ({tamanho:.1f} KB)")
            
            # Mostrar qual foi carregado
            st.write(f"\n**Arquivo atual carregado:** {len(df)} registros")
            
    except Exception as e:
        st.info("Informa√ß√µes do arquivo n√£o dispon√≠veis")
    
    # Download
    st.markdown("---")
    st.subheader("üì• Download")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üìä Dataset Completo",
            data=csv,
            file_name='dataset_completo.csv',
            mime='text/csv',
        )
    
    with col2:
        if len(colunas_numericas) > 0:
            csv_numerico = df[colunas_numericas].to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üî¢ Apenas Num√©ricas",
                data=csv_numerico,
                file_name='dados_numericos.csv',
                mime='text/csv',
            )
    
    with col3:
        csv_estatisticas = df.describe().to_csv().encode('utf-8')
        st.download_button(
            label="üìà Estat√≠sticas",
            data=csv_estatisticas,
            file_name='estatisticas.csv',
            mime='text/csv',
        )

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666;'>
    <p>üêæ VetDiagnosisAI - Sistema de Apoio ao Diagn√≥stico Veterin√°rio</p>
    <p>Desenvolvido para o MBA - Sistema Completo com Datasets Reais</p>
</div>
""", unsafe_allow_html=True)
